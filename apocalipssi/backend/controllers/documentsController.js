const mongoose = require("mongoose")
const fs = require("fs")
const Document = require("../models/documentsModel")
const pdf = require("pdf-parse")

// Fonction utilitaire pour t√©l√©charger le mod√®le si n√©cessaire
const ensureModelExists = async (modelName = "llama3.2:1b") => {
  try {
    const ollamaUrl = process.env.OLLAMA_URL || "http://localhost:11434"

    // V√©rifier si le mod√®le existe
    const listResponse = await fetch(`${ollamaUrl}/api/tags`)
    if (listResponse.ok) {
      const models = await listResponse.json()
      const modelExists = models.models?.some((model) => model.name === modelName)

      if (!modelExists) {
        console.log(`üì• T√©l√©chargement du mod√®le ${modelName}...`)

        // T√©l√©charger le mod√®le
        const pullResponse = await fetch(`${ollamaUrl}/api/pull`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ name: modelName }),
        })

        if (!pullResponse.ok) {
          throw new Error(`Erreur lors du t√©l√©chargement du mod√®le: ${pullResponse.status}`)
        }

        console.log(`‚úÖ Mod√®le ${modelName} t√©l√©charg√© avec succ√®s`)
      }
    }
  } catch (error) {
    console.warn(`‚ö†Ô∏è Impossible de v√©rifier/t√©l√©charger le mod√®le: ${error.message}`)
  }
}

// Fonction pour nettoyer et parser le JSON de l'IA - Version am√©lior√©e
const parseAIResponse = (responseText) => {
  try {
    console.log("ü§ñ R√©ponse brute compl√®te:", responseText)

    // Nettoyer la r√©ponse
    let cleanedText = responseText.trim()

    // Enlever les balises markdown si pr√©sentes
    cleanedText = cleanedText.replace(/```json\s*/g, "").replace(/```\s*/g, "")

    // Chercher le JSON dans la r√©ponse (plusieurs patterns)
    let jsonMatch = cleanedText.match(/\{[\s\S]*\}/)

    if (!jsonMatch) {
      // Essayer de trouver un JSON sur plusieurs lignes
      jsonMatch = cleanedText.match(/\{[^}]*"resume"[^}]*\}/s)
    }

    if (jsonMatch) {
      const jsonString = jsonMatch[0]
      console.log("üîç JSON extrait:", jsonString)

      // Parser le JSON
      const parsed = JSON.parse(jsonString)

      // V√©rifier que les cl√©s requises existent
      if (parsed.resume && parsed.points_cles && parsed.suggestions_actions) {
        console.log("‚úÖ JSON valide trouv√©")

        // V√©rifier si le mod√®le a simplement r√©p√©t√© le template
        const isTemplateRepeat =
            parsed.resume.includes("Un r√©sum√© concis du document") &&
            parsed.points_cles.some((p) => p.includes("point cl√© important du document")) &&
            parsed.suggestions_actions.some((a) => a.includes("action recommand√©e"))

        if (isTemplateRepeat) {
          console.log("‚ö†Ô∏è Le mod√®le a r√©p√©t√© le template au lieu de l'analyser")
          return {
            success: false,
            rawText: responseText,
            error: "Le mod√®le a r√©p√©t√© le template",
          }
        }

        return {
          success: true,
          data: parsed,
        }
      } else {
        console.log("‚ùå JSON incomplet, cl√©s manquantes")
      }
    }

    // Si pas de JSON trouv√©, essayer de cr√©er un JSON √† partir du texte brut
    console.log("üîÑ Tentative de cr√©ation de JSON √† partir du texte brut")

    const lines = cleanedText.split("\n").filter((line) => line.trim())
    let resume = ""
    const points = []
    const actions = []

    // Essayer d'extraire des informations du texte brut
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i].trim()
      if (line.length > 20 && !resume) {
        resume = line.substring(0, 200) + (line.length > 200 ? "..." : "")
      }
      if (line.includes("‚Ä¢") || line.includes("-") || line.includes("*")) {
        if (points.length < 4) {
          points.push(line.replace(/[‚Ä¢\-*]\s*/, "").trim())
        }
      }
    }

    // Fallback avec contenu extrait
    if (resume || points.length > 0) {
      return {
        success: true,
        data: {
          resume: resume || "R√©sum√© du document analys√© par l'IA locale",
          points_cles:
              points.length > 0
                  ? points
                  : [
                    "Document PDF trait√© avec succ√®s",
                    "Contenu extrait et analys√©",
                    "Informations disponibles pour consultation",
                    "Pr√™t pour traitement manuel",
                  ],
          suggestions_actions: [
            "Consulter le contenu extrait",
            "R√©viser les informations manuellement",
            "Organiser selon vos besoins",
          ],
        },
        extracted_from_raw: true,
      }
    }

    return {
      success: false,
      rawText: responseText,
    }
  } catch (error) {
    console.error("‚ùå Erreur parsing JSON:", error)
    return {
      success: false,
      rawText: responseText,
      error: error.message,
    }
  }
}

// Fonction pour g√©n√©rer une analyse basique √† partir du texte du PDF
const generateBasicAnalysis = (text) => {
  try {
    // Extraire les premi√®res phrases pour le r√©sum√©
    const sentences = text.split(/[.!?]+/).filter((s) => s.trim().length > 10)
    const firstSentences = sentences.slice(0, 2).join(". ").trim() + "."

    // Extraire des mots-cl√©s potentiels (mots qui apparaissent fr√©quemment)
    const words = text
        .toLowerCase()
        .replace(/[^\w\s]/g, "")
        .split(/\s+/)
        .filter((word) => word.length > 4)

    const wordFrequency = {}
    words.forEach((word) => {
      wordFrequency[word] = (wordFrequency[word] || 0) + 1
    })

    // Trier par fr√©quence et prendre les 5 premiers
    const keywords = Object.entries(wordFrequency)
        .sort((a, b) => b[1] - a[1])
        .slice(0, 5)
        .map((entry) => entry[0])

    // Extraire des paragraphes potentiellement importants (plus longs)
    const paragraphs = text
        .split("\n\n")
        .filter((p) => p.trim().length > 50)
        .sort((a, b) => b.length - a.length)

    // Cr√©er des points cl√©s √† partir des mots-cl√©s et paragraphes
    const points_cles = [
      `Le document contient des r√©f√©rences √† "${keywords.slice(0, 2).join('" et "')}"`,
      `Un sujet important semble √™tre li√© √† "${keywords[2] || keywords[0]}"`,
      `Le document comporte ${paragraphs.length} paragraphes principaux`,
      `Longueur totale: ${text.length} caract√®res (environ ${Math.round(text.length / 6)} mots)`,
    ]

    // Suggestions d'actions bas√©es sur le contenu - Maintenant des questions pour le chat
    const suggestions_actions = [
      "Peux-tu me donner plus de d√©tails sur " + (keywords[0] || "le sujet principal") + " ?",
      "Quels sont les points les plus importants √† retenir de ce document ?",
      "Y a-t-il des actions concr√®tes recommand√©es dans ce document ?",
    ]

    return {
      resume: firstSentences,
      points_cles,
      suggestions_actions,
      texte_extrait_pdf: text.substring(0, 1000) + (text.length > 1000 ? "..." : ""),
      note_generation: "Analyse g√©n√©r√©e automatiquement √† partir du contenu du document",
    }
  } catch (error) {
    console.error("Erreur lors de la g√©n√©ration de l'analyse basique:", error)
    return {
      resume: "Document PDF analys√© avec succ√®s. Contenu disponible pour consultation.",
      points_cles: [
        "Document PDF trait√© avec succ√®s",
        `Contient ${text.length} caract√®res de texte`,
        "Pr√™t pour analyse manuelle",
        "Contenu extrait et disponible",
      ],
      suggestions_actions: [
        "Peux-tu r√©sumer les points principaux de ce document ?",
        "Quelles sont les informations les plus importantes ?",
        "Comment puis-je utiliser ces informations ?",
      ],
      texte_extrait_pdf: text.substring(0, 1000) + (text.length > 1000 ? "..." : ""),
    }
  }
}

// üì§ Upload
exports.uploadDocument = async (req, res) => {
  if (!req.file) return res.status(400).json({ message: "Aucun fichier re√ßu" })

  try {
    const bucket = new mongoose.mongo.GridFSBucket(mongoose.connection.db, {
      bucketName: "documents",
    })

    const uploadStream = bucket.openUploadStream(req.file.originalname)
    const fileStream = fs.createReadStream(req.file.path)

    fileStream
        .pipe(uploadStream)
        .on("error", (err) => {
          return res.status(500).json({ message: "Erreur lors de l'upload", error: err.message })
        })
        .on("finish", async () => {
          // Supprimer fichier temporaire
          fs.unlinkSync(req.file.path)

          const doc = new Document({
            username: req.body.username,
            fileId: uploadStream.id,
            originalName: req.file.originalname,
          })

          await doc.save()

          res.status(201).json({ message: "Fichier upload√© avec succ√®s", document: doc })
        })
  } catch (err) {
    res.status(500).json({ message: "Erreur serveur", error: err.message })
  }
}

// üìã Liste
exports.getAllDocuments = async (req, res) => {
  try {
    const docs = await Document.find()
    res.json(docs)
  } catch (err) {
    res.status(500).json({ message: err.message })
  }
}

// T√©l√©chargement
exports.downloadDocument = async (req, res) => {
  const gfs = req.app.locals.gfs
  if (!gfs) return res.status(500).json({ message: "GridFS non initialis√©" })

  try {
    const fileId = new mongoose.Types.ObjectId(req.params.fileId)
    const filesCursor = await gfs.find({ _id: fileId })
    const files = await filesCursor.toArray()
    if (!files || files.length === 0) {
      return res.status(404).json({ message: "Fichier introuvable" })
    }
    const file = files[0]

    res.set("Content-Type", file.contentType || "application/octet-stream")
    res.set("Content-Disposition", `attachment; filename="${file.filename}"`)

    const downloadStream = gfs.openDownloadStream(file._id)
    downloadStream.pipe(res)
  } catch (err) {
    res.status(500).json({ message: err.message })
  }
}

// Suppression
exports.deleteDocument = async (req, res) => {
  const gfs = req.app.locals.gfs
  if (!gfs) return res.status(500).json({ message: "GridFS non initialis√©" })

  try {
    const doc = await Document.findById(req.params.id)
    if (!doc) return res.status(404).json({ message: "Document non trouv√©" })

    await gfs.delete(doc.fileId)
    await doc.deleteOne()
    res.json({ message: "Document et fichier supprim√©s avec succ√®s" })
  } catch (err) {
    res.status(500).json({ message: err.message })
  }
}

// ü§ñ Analyse IA avec mod√®le local (Ollama)
exports.analyzeDocument = async (req, res) => {
  const gfs = req.app.locals.gfs
  if (!gfs) return res.status(500).json({ message: "GridFS non initialis√©" })

  try {
    const doc = await Document.findById(req.params.id)
    if (!doc) return res.status(404).json({ message: "Document non trouv√©" })

    // T√©l√©charger le fichier depuis GridFS
    const downloadStream = gfs.openDownloadStream(doc.fileId)
    const chunks = []

    downloadStream.on("data", (chunk) => chunks.push(chunk))
    downloadStream.on("error", (err) => {
      return res.status(500).json({ message: "Erreur lors du t√©l√©chargement", error: err.message })
    })

    downloadStream.on("end", async () => {
      try {
        const buffer = Buffer.concat(chunks)

        // Extraire le texte du PDF
        const pdfData = await pdf(buffer)
        const text = pdfData.text

        if (!text || text.trim().length === 0) {
          return res.status(400).json({ message: "Impossible d'extraire le texte du PDF" })
        }

        // G√©n√©rer une analyse basique √† partir du texte du PDF
        const basicAnalysis = generateBasicAnalysis(text)

        try {
          // S'assurer que le mod√®le existe
          await ensureModelExists("llama3.2:1b")

          // Pr√©parer le prompt pour l'IA locale - Version am√©lior√©e
          const prompt = `Tu es un assistant IA sp√©cialis√© dans l'analyse de documents. 
  
IMPORTANT: Analyse le document suivant et r√©ponds UNIQUEMENT avec un objet JSON valide, sans aucun texte avant ou apr√®s.

Voici le document √† analyser :
${text.substring(0, 2000)}

G√©n√®re un JSON avec cette structure exacte, en rempla√ßant les exemples par ton analyse r√©elle du document:

{
  "resume": "√âcris ici un r√©sum√© concis du document en 2-3 phrases",
  "points_cles": [
    "Premier point important que tu as identifi√© dans le document",
    "Deuxi√®me point important que tu as identifi√© dans le document", 
    "Troisi√®me point important que tu as identifi√© dans le document",
    "Quatri√®me point important que tu as identifi√© dans le document"
  ],
  "suggestions_actions": [
    "Premi√®re question que l'utilisateur pourrait poser sur ce document",
    "Deuxi√®me question que l'utilisateur pourrait poser sur ce document",
    "Troisi√®me question que l'utilisateur pourrait poser sur ce document"
  ]
}

REMPLACE les exemples ci-dessus par ton analyse r√©elle du document. Les suggestions_actions doivent √™tre des questions que l'utilisateur pourrait poser.`

          const ollamaUrl = process.env.OLLAMA_URL || "http://localhost:11434"

          console.log("ü§ñ Envoi de la requ√™te √† Ollama...")

          // Appel √† Ollama (mod√®le local)
          const response = await fetch(`${ollamaUrl}/api/generate`, {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({
              model: "llama3.2:1b",
              prompt: prompt,
              stream: false,
              options: {
                temperature: 0.3,
                top_p: 0.8,
                num_predict: 600,
                stop: ["\n\n", "```"],
              },
            }),
          })

          if (!response.ok) {
            throw new Error(`Erreur Ollama: ${response.status} - ${response.statusText}`)
          }

          const aiResponse = await response.json()
          const analysisText = aiResponse.response || ""

          console.log("ü§ñ R√©ponse brute de l'IA:", analysisText)

          // Parser la r√©ponse de l'IA
          const parseResult = parseAIResponse(analysisText)

          if (parseResult.success) {
            console.log("‚úÖ Analyse IA r√©ussie:", parseResult.data)

            // Utiliser l'analyse de l'IA
            res.json({
              document: {
                id: doc._id,
                nom_original: doc.originalName,
                utilisateur: doc.username,
                date_upload: doc.uploadDate,
              },
              analyse: parseResult.data,
              texte_document: text, // Ajouter le texte complet pour le chat
              metadata: {
                nombre_pages: pdfData.numpages,
                longueur_texte: text.length,
                date_analyse: new Date(),
                modele_utilise: "llama3.2:1b (local)",
                parsing_success: true,
              },
            })
          } else {
            console.log("‚ö†Ô∏è √âchec de l'analyse IA, utilisation de l'analyse basique")

            // Utiliser l'analyse basique g√©n√©r√©e √† partir du texte
            res.json({
              document: {
                id: doc._id,
                nom_original: doc.originalName,
                utilisateur: doc.username,
                date_upload: doc.uploadDate,
              },
              analyse: {
                ...basicAnalysis,
                texte_complet_ia: parseResult.rawText,
                erreur_parsing: parseResult.error || "Format JSON non reconnu",
              },
              texte_document: text, // Ajouter le texte complet pour le chat
              metadata: {
                nombre_pages: pdfData.numpages,
                longueur_texte: text.length,
                date_analyse: new Date(),
                modele_utilise: "llama3.2:1b (local) + analyse automatique",
                parsing_success: false,
              },
            })
          }
        } catch (aiError) {
          console.error("Erreur lors de l'analyse IA:", aiError)

          // En cas d'erreur avec l'IA, utiliser directement l'analyse basique
          res.json({
            document: {
              id: doc._id,
              nom_original: doc.originalName,
              utilisateur: doc.username,
              date_upload: doc.uploadDate,
            },
            analyse: {
              ...basicAnalysis,
              erreur_ia: aiError.message,
            },
            texte_document: text, // Ajouter le texte complet pour le chat
            metadata: {
              nombre_pages: pdfData.numpages,
              longueur_texte: text.length,
              date_analyse: new Date(),
              modele_utilise: "Analyse automatique (erreur IA)",
              parsing_success: false,
            },
          })
        }
      } catch (error) {
        console.error("Erreur lors de l'analyse:", error)

        // Fallback en cas d'erreur g√©n√©rale
        res.json({
          document: {
            id: doc._id,
            nom_original: doc.originalName,
            utilisateur: doc.username,
            date_upload: doc.uploadDate,
          },
          analyse: {
            resume:
                "Erreur lors de l'analyse automatique. Le document a √©t√© trait√© avec succ√®s mais l'analyse n'est pas disponible.",
            points_cles: ["Document PDF trait√©", "Texte extrait avec succ√®s", "Analyse temporairement indisponible"],
            suggestions_actions: [
              "Peux-tu m'aider √† comprendre ce document ?",
              "Quelles sont les informations principales ?",
              "Comment puis-je utiliser ce document ?",
            ],
            erreur_ia: error.message,
          },
          metadata: {
            nombre_pages: 0,
            longueur_texte: 0,
            date_analyse: new Date(),
            modele_utilise: "Fallback (erreur syst√®me)",
          },
        })
      }
    })
  } catch (err) {
    console.error("Erreur g√©n√©rale:", err)
    res.status(500).json({ message: "Erreur serveur", error: err.message })
  }
}

// üí¨ Chat avec l'IA sur un document
exports.chatWithDocument = async (req, res) => {
  try {
    const { message, documentText, conversationHistory } = req.body

    if (!message) {
      return res.status(400).json({ message: "Message requis" })
    }

    // S'assurer que le mod√®le existe
    await ensureModelExists("llama3.2:1b")

    // Construire le contexte de conversation
    let conversationContext = ""
    if (conversationHistory && conversationHistory.length > 0) {
      conversationContext = conversationHistory
          .map((msg) => `${msg.role === "user" ? "Utilisateur" : "Assistant"}: ${msg.content}`)
          .join("\n")
    }

    // Pr√©parer le prompt pour le chat
    const prompt = `Tu es un assistant IA sp√©cialis√© dans l'analyse de documents. Tu discutes avec un utilisateur √† propos d'un document sp√©cifique.

CONTEXTE DU DOCUMENT:
${documentText ? documentText.substring(0, 3000) : "Document non disponible"}

${conversationContext ? `HISTORIQUE DE CONVERSATION:\n${conversationContext}\n` : ""}

NOUVELLE QUESTION DE L'UTILISATEUR:
${message}

R√©ponds de mani√®re naturelle et utile en te basant sur le contenu du document. Sois concis mais informatif.`

    const ollamaUrl = process.env.OLLAMA_URL || "http://localhost:11434"

    console.log("üí¨ Envoi de la question √† l'IA:", message)

    // Appel √† Ollama pour le chat
    const response = await fetch(`${ollamaUrl}/api/generate`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama3.2:1b",
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.4,
          top_p: 0.9,
          num_predict: 400,
        },
      }),
    })

    if (!response.ok) {
      throw new Error(`Erreur Ollama: ${response.status} - ${response.statusText}`)
    }

    const aiResponse = await response.json()
    const aiMessage = aiResponse.response || "D√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse."

    console.log("üí¨ R√©ponse de l'IA:", aiMessage)

    res.json({
      response: aiMessage.trim(),
      timestamp: new Date(),
    })
  } catch (error) {
    console.error("Erreur lors du chat:", error)
    res.status(500).json({
      message: "Erreur lors de la g√©n√©ration de la r√©ponse",
      error: error.message,
    })
  }
}
